---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Honghua Dong et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-07-27 15:27:10'
tags:
- apple
- apple watch
theme: light
title: APPL A Prompt Programming Language for Harmonious Integration of Programs and
  Large Language Model Prompts
---

# title: APPL A Prompt Programming Language for Harmonious Integration of Programs and Large Language Model Prompts 
## publish date: 
**2024-06-19** 
## authors: 
  Honghua Dong et.al. 
## paper id
2406.13161v1
## download
[2406.13161v1](http://arxiv.org/abs/2406.13161v1)
## abstracts:
Large Language Models (LLMs) have become increasingly capable of handling diverse tasks with the aid of well-crafted prompts and integration of external tools, but as task complexity rises, the workflow involving LLMs can be complicated and thus challenging to implement and maintain. To address this challenge, we propose APPL, A Prompt Programming Language that acts as a bridge between computer programs and LLMs, allowing seamless embedding of prompts into Python functions, and vice versa. APPL provides an intuitive and Python-native syntax, an efficient parallelized runtime with asynchronous semantics, and a tracing module supporting effective failure diagnosis and replaying without extra costs. We demonstrate that APPL programs are intuitive, concise, and efficient through three representative scenarios: Chain-of-Thought with self-consistency (CoT-SC), ReAct tool use agent, and multi-agent chat. Experiments on three parallelizable workflows further show that APPL can effectively parallelize independent LLM calls, with a significant speedup ratio that almost matches the estimation.
## QA:
coming soon
